{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7040dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_data(folder_path):\n",
    "    extracted_data = {}\n",
    "    suffix_counter = {}\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        base_name, ext = os.path.splitext(file_name)\n",
    "\n",
    "        if ext.lower() in ['.csv', '.xlsx', '.xls']:\n",
    "            try:\n",
    "                if ext.lower() == '.csv':\n",
    "                    # Single DataFrame for CSV\n",
    "                    df_dict = {base_name: pd.read_csv(file_path)}\n",
    "                else:\n",
    "                    # Read all sheets into a dict of DataFrames\n",
    "                    df_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "                    # Prefix sheet names with base filename\n",
    "                    df_dict = {f\"{base_name}_{sheet_name}\": df\n",
    "                               for sheet_name, df in df_dict.items()}\n",
    "\n",
    "                for key, df in df_dict.items():\n",
    "                    unique_key = key\n",
    "                    # Handle key collisions\n",
    "                    if unique_key in extracted_data:\n",
    "                        # Initialize counter for this key if needed\n",
    "                        if key not in suffix_counter:\n",
    "                            suffix_counter[key] = 1\n",
    "                        suffix_counter[key] += 1\n",
    "                        unique_key = f\"{key}_{suffix_counter[key]}\"\n",
    "\n",
    "                    extracted_data[unique_key] = df\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ddfc08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify full folder path to the dataset\n",
    "df = extract_data(\"C:/Users/USER/Downloads/Hackathon/AgricConnect-PHL/dataset/harvest_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "467fa1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['harvested_area_Total Area (TA)', 'harvested_area_Irrigated Portion (TR)', 'harvested_area_Total Area(TA)', 'harvested_area_Irrigated Portion (TI)', 'harvested_area_Rainfed Portion(TR)', 'Physical_area_Total Area (TA)', 'Physical_area_Sheet1', 'Physical_area_Irrigated Portion (TI)', 'Physical_area_Rainfed Portion (TR)', 'Production_Total Area (TA)', 'Production_Irrigated Portion (TI)', 'Production_Rainfed Portion (TR)', 'yield_Total Area (TA)', 'yield_Irrigated Portion (TI)', 'yield_Rainfed Portion (TR)'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(sheets_dict: dict[pd.DataFrame], \n",
    "                   lookup: dict[str,str], \n",
    "                   file_origin: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    sheets_dict: { sheet_name: DataFrame, ... }\n",
    "    lookup: { \"whea\": \"Wheat\", ..., \"x\": \"latitude of pixel center\", \"y\": \"longitude of pixel center\" }\n",
    "    file_origin: one of \"harvested_area\", \"physical_area\", \"yield\", \"production\"\n",
    "    \"\"\"\n",
    "    # mapping from file_origin to rec_type letter\n",
    "    rec_map = {\n",
    "        \"harvested_area\": \"H\",\n",
    "        \"physical_area\":  \"A\",\n",
    "        \"yield\":          \"Y\",\n",
    "        \"production\":     \"P\"\n",
    "    }\n",
    "    # mapping tech suffix → human label\n",
    "    tech_map = {\n",
    "        \"A\": \"all technologies\",\n",
    "        \"I\": \"irrigation\",\n",
    "        \"R\": \"rainfed\"\n",
    "    }\n",
    "    rec_code = rec_map[file_origin]\n",
    "    \n",
    "    long_dfs = []\n",
    "    for sheet_name, df in sheets_dict.items():\n",
    "        # 1) infer tech_type from sheet name suffix (_TA, _TI, _TR → A, I, R)\n",
    "        if sheet_name.endswith(\"_TA\"):\n",
    "            tech = \"A\"\n",
    "        elif sheet_name.endswith(\"_TI\"):\n",
    "            tech = \"I\"\n",
    "        elif sheet_name.endswith(\"_TR\"):\n",
    "            tech = \"R\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unrecognized tech suffix in '{sheet_name}'\")\n",
    "        \n",
    "        # 2) Rename x/y → latitude/longitude\n",
    "        df = df.rename(columns={\n",
    "            \"x\": lookup[\"x\"],\n",
    "            \"y\": lookup[\"y\"]\n",
    "        })\n",
    "        \n",
    "        # 3) Rename each crop column: e.g. BANA_I → Banana_I\n",
    "        rename_map = {}\n",
    "        for col in df.columns:\n",
    "            if col.upper().endswith(f\"_{tech}\"):\n",
    "                prefix = col.rsplit(\"_\", 1)[0].lower()  # e.g. \"bana\"\n",
    "                full_crop = lookup.get(prefix)\n",
    "                if full_crop is None:\n",
    "                    # skip any non-crop or unexpected\n",
    "                    continue\n",
    "                rename_map[col] = f\"{full_crop}_{tech}\"\n",
    "        df = df.rename(columns=rename_map)\n",
    "        \n",
    "        # 4) Melt to long: keep all non-crop columns as id_vars\n",
    "        crop_cols = list(rename_map.values())\n",
    "        id_vars = [c for c in df.columns if c not in crop_cols]\n",
    "        df_long = df.melt(\n",
    "            id_vars=id_vars,\n",
    "            value_vars=crop_cols,\n",
    "            var_name=\"variable\",\n",
    "            value_name=\"value\"\n",
    "        )\n",
    "        \n",
    "        # 5) Split “variable” → Crop type & tech_type\n",
    "        df_long[\"tech_type\"] = df_long[\"variable\"].str[-1]\n",
    "        df_long[\"Crop type\"] = df_long[\"variable\"].str[:-2]\n",
    "        df_long = df_long.drop(columns=[\"variable\"])\n",
    "        \n",
    "        # 6) Add water‐management regime & rec_type\n",
    "        df_long[\"water‐management regime\"] = df_long[\"tech_type\"].map(tech_map)\n",
    "        df_long[\"rec_type\"] = rec_code\n",
    "        \n",
    "        # 7) Reorder & select final columns\n",
    "        final_cols = [\n",
    "            lookup[\"y\"],              # latitude of pixel center\n",
    "            lookup[\"x\"],              # longitude of pixel center\n",
    "            \"Crop type\",\n",
    "            \"tech_type\",\n",
    "            \"water‐management regime\",\n",
    "            \"rec_type\",\n",
    "            \"ADM1_NAME\",\n",
    "            \"ADM2_NAME\",\n",
    "            \"unit\",\n",
    "            \"grid_code\",\n",
    "            \"year_data\",\n",
    "            \"value\"\n",
    "        ]\n",
    "        # (rename latitude/longitude to the exact strings)\n",
    "        df_long = df_long[final_cols]\n",
    "        \n",
    "        long_dfs.append(df_long)\n",
    "    \n",
    "    # 8) Concatenate all tech-types for this file\n",
    "    result = pd.concat(long_dfs, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "# import json\n",
    "# lookup = json.load(open(\"lookup.json\"))\n",
    "# harvested_sheets = pd.read_excel(\"harvested_area.xlsx\", sheet_name=None)\n",
    "# ha_long = transform_data(harvested_sheets, lookup, \"harvested_area\")\n",
    "# physical_sheets = pd.read_excel(\"physical_area.xlsx\", sheet_name=None)\n",
    "# pa_long = transform_data(physical_sheets, lookup, \"physical_area\")\n",
    "# ... and similarly for yield & production\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266058d1",
   "metadata": {
    "vscode": {
     "languageId": "lua"
    }
   },
   "outputs": [],
   "source": [
    "# Define the lookup dictionary\n",
    "lookup = \"lookup.json\"\n",
    "\n",
    "# Transform the data for each file origin\n",
    "harvested_long = transform_data(\n",
    "    {k: v for k, v in df.items() if \"harvested_area\" in k.lower()},\n",
    "    lookup,\n",
    "    \"harvested_area\"\n",
    ")\n",
    "\n",
    "physical_long = transform_data(\n",
    "    {k: v for k, v in df.items() if \"physical_area\" in k.lower()},\n",
    "    lookup,\n",
    "    \"physical_area\"\n",
    ")\n",
    "\n",
    "yield_long = transform_data(\n",
    "    {k: v for k, v in df.items() if \"yield\" in k.lower()},\n",
    "    lookup,\n",
    "    \"yield\"\n",
    ")\n",
    "\n",
    "production_long = transform_data(\n",
    "    {k: v for k, v in df.items() if \"production\" in k.lower()},\n",
    "    lookup,\n",
    "    \"production\"\n",
    ")\n",
    "\n",
    "# Example: Display the transformed data for harvested_area\n",
    "print(harvested_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05403a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45d14d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da3f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5025b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7caf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
